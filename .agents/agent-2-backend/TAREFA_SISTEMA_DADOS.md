# üöÄ TAREFA AGENT 2: Sistema de Dados e Cache

**Prioridade:** üî¥ CR√çTICA
**Estimativa:** 6-8 horas
**Status:** üü° PENDENTE

---

## üéØ OBJETIVO

Criar a **camada de dados** do sistema:
- Tabelas para armazenar funcion√°rios e cache SERPRO
- Endpoints para dashboard ler dados (sem custo)
- Sistema de jobs para processar consultas em background
- Cron job para atualizar cache automaticamente

---

## üìã CHECKLIST GERAL

- [ ] 1. Criar migration `002_dados_investigacao.sql`
- [ ] 2. Aplicar migration no D1 remoto
- [ ] 3. Criar endpoints de importa√ß√£o
- [ ] 4. Criar endpoints de leitura (dashboard)
- [ ] 5. Implementar processador de jobs
- [ ] 6. Configurar cron trigger
- [ ] 7. Testar fluxo completo
- [ ] 8. Documentar para Agent 3
- [ ] 9. Deploy e valida√ß√£o

---

## üìÅ TAREFA 1: Migration - Tabelas de Dados

**Arquivo:** `backend/workers/database/migrations/002_dados_investigacao.sql`

```sql
-- ============================================================================
-- INVESTIGAREE - SISTEMA DE DADOS E CACHE
-- Migration: 002_dados_investigacao.sql
-- Created: 2025-12-07
-- Agent: Agent 2 - Backend Engineer
-- ============================================================================

-- ============================================================================
-- TABELA: funcionarios
-- Armazena lista de funcion√°rios por tenant
-- ============================================================================
CREATE TABLE IF NOT EXISTS funcionarios (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  tenant_code TEXT NOT NULL,
  cpf TEXT NOT NULL,

  -- Dados b√°sicos (importados do CSV)
  nome_importado TEXT,              -- Nome do CSV (pode diferir do SERPRO)
  grupo TEXT,                       -- COMURG, SECRETARIA, etc.
  cargo TEXT,
  salario REAL,

  -- Dados enriquecidos (outras fontes)
  esta_morto INTEGER DEFAULT 0,     -- 0=n√£o, 1=sim (via SISOBITO)
  ano_obito INTEGER,
  recebe_beneficio INTEGER DEFAULT 0,
  qual_beneficio TEXT,
  socio_empresa INTEGER DEFAULT 0,
  qtd_empresas INTEGER DEFAULT 0,
  doador_campanha INTEGER DEFAULT 0,
  valor_doacoes REAL,
  candidato INTEGER DEFAULT 0,
  sancionado_ceis INTEGER DEFAULT 0,
  sancionado_ofac INTEGER DEFAULT 0,

  -- Metadados
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,

  -- Constraints
  UNIQUE(tenant_code, cpf),
  FOREIGN KEY (tenant_code) REFERENCES tenants(tenant_code)
);

-- ============================================================================
-- TABELA: serpro_cpf_cache
-- Cache de consultas CPF (SERPRO API)
-- Validade: 90 dias
-- ============================================================================
CREATE TABLE IF NOT EXISTS serpro_cpf_cache (
  cpf TEXT PRIMARY KEY,

  -- Dados principais
  nome TEXT NOT NULL,
  nascimento TEXT,                  -- DD/MM/YYYY
  situacao_codigo TEXT,             -- "0" = regular, "2" = suspensa, etc.
  situacao_descricao TEXT,          -- "REGULAR", "SUSPENSA", etc.

  -- Resposta completa (backup)
  dados_json TEXT NOT NULL,         -- JSON completo da resposta SERPRO

  -- Controle de cache
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  expires_at DATETIME NOT NULL,     -- Data de expira√ß√£o (created_at + 90 dias)
  consultas_count INTEGER DEFAULT 1, -- Contador de re-consultas

  -- Metadados
  ultimo_erro TEXT,                 -- √öltima mensagem de erro (se houver)
  ultimo_status_http INTEGER        -- √öltimo status HTTP da API SERPRO
);

-- ============================================================================
-- TABELA: serpro_cnpj_cache
-- Cache de consultas CNPJ (SERPRO API)
-- Validade: 180 dias (empresas mudam menos)
-- ============================================================================
CREATE TABLE IF NOT EXISTS serpro_cnpj_cache (
  cnpj TEXT PRIMARY KEY,

  -- Dados principais
  razao_social TEXT NOT NULL,
  nome_fantasia TEXT,
  situacao_cadastral TEXT,          -- "ATIVA", "BAIXADA", "SUSPENSA"
  data_situacao_cadastral TEXT,

  -- QSA (Quadro Societ√°rio e Administradores)
  qsa_json TEXT,                    -- JSON com lista de s√≥cios

  -- Resposta completa (backup)
  dados_json TEXT NOT NULL,

  -- Controle de cache
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  expires_at DATETIME NOT NULL,     -- created_at + 180 dias
  consultas_count INTEGER DEFAULT 1,

  -- Metadados
  ultimo_erro TEXT,
  ultimo_status_http INTEGER
);

-- ============================================================================
-- TABELA: jobs_queue
-- Fila de processamento em background
-- ============================================================================
CREATE TABLE IF NOT EXISTS jobs_queue (
  id INTEGER PRIMARY KEY AUTOINCREMENT,

  -- Identifica√ß√£o
  type TEXT NOT NULL,               -- Tipo de job (ver tipos abaixo)
  tenant_code TEXT,                 -- Tenant associado (nullable para jobs globais)

  -- Status
  status TEXT NOT NULL DEFAULT 'pending', -- pending, processing, completed, failed
  priority INTEGER DEFAULT 5,       -- 1-10 (1=highest, 10=lowest)

  -- Dados
  data_json TEXT,                   -- JSON com par√¢metros do job

  -- Progresso
  progress INTEGER DEFAULT 0,       -- 0-100
  items_total INTEGER,              -- Total de itens a processar
  items_processed INTEGER DEFAULT 0, -- Itens j√° processados
  items_failed INTEGER DEFAULT 0,   -- Itens que falharam

  -- Erro
  error TEXT,                       -- Mensagem de erro (se falhou)
  error_details TEXT,               -- Stack trace ou detalhes

  -- Retry
  retry_count INTEGER DEFAULT 0,    -- Tentativas realizadas
  max_retries INTEGER DEFAULT 3,    -- M√°ximo de tentativas

  -- Timestamps
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  started_at DATETIME,
  completed_at DATETIME,
  next_retry_at DATETIME,           -- Quando tentar novamente (se falhou)

  -- Constraints
  FOREIGN KEY (tenant_code) REFERENCES tenants(tenant_code)
);

-- ============================================================================
-- TIPOS DE JOBS (Documenta√ß√£o)
-- ============================================================================
-- 'import_cpf'           - Importar lista de CPFs do CSV
-- 'consultar_cpf_batch'  - Consultar lote de CPFs no SERPRO
-- 'consultar_cnpj_batch' - Consultar lote de CNPJs no SERPRO
-- 'refresh_cache_cpf'    - Atualizar CPFs expirados
-- 'refresh_cache_cnpj'   - Atualizar CNPJs expirados
-- 'enriquecer_dados'     - Buscar dados em outras fontes (SISOBITO, TSE, etc.)

-- ============================================================================
-- INDEXES PARA PERFORMANCE
-- ============================================================================

-- funcionarios
CREATE INDEX IF NOT EXISTS idx_funcionarios_tenant ON funcionarios(tenant_code);
CREATE INDEX IF NOT EXISTS idx_funcionarios_cpf ON funcionarios(cpf);
CREATE INDEX IF NOT EXISTS idx_funcionarios_grupo ON funcionarios(tenant_code, grupo);

-- serpro_cpf_cache
CREATE INDEX IF NOT EXISTS idx_serpro_cpf_expires ON serpro_cpf_cache(expires_at);
CREATE INDEX IF NOT EXISTS idx_serpro_cpf_updated ON serpro_cpf_cache(updated_at);

-- serpro_cnpj_cache
CREATE INDEX IF NOT EXISTS idx_serpro_cnpj_expires ON serpro_cnpj_cache(expires_at);
CREATE INDEX IF NOT EXISTS idx_serpro_cnpj_updated ON serpro_cnpj_cache(updated_at);

-- jobs_queue
CREATE INDEX IF NOT EXISTS idx_jobs_status ON jobs_queue(status, priority, created_at);
CREATE INDEX IF NOT EXISTS idx_jobs_tenant ON jobs_queue(tenant_code, status);
CREATE INDEX IF NOT EXISTS idx_jobs_type ON jobs_queue(type, status);
CREATE INDEX IF NOT EXISTS idx_jobs_next_retry ON jobs_queue(next_retry_at);

-- ============================================================================
-- MIGRATION COMPLETA
-- ============================================================================
```

**Checklist:**
- [ ] Criar arquivo `002_dados_investigacao.sql`
- [ ] Aplicar migration: `npx wrangler d1 execute investigaree-db --remote --file=migrations/002_dados_investigacao.sql`
- [ ] Verificar tabelas criadas: `npx wrangler d1 execute investigaree-db --remote --command="SELECT name FROM sqlite_master WHERE type='table'"`

---

## üì° TAREFA 2: Endpoint - Importar Funcion√°rios

**Arquivo:** `backend/workers/api/src/routes/dados.routes.ts` (novo)

```typescript
import { Hono } from 'hono';
import { authMiddleware } from '../middleware/auth';
import type { Env } from '../types/api.types';

const router = new Hono<{ Bindings: Env }>();

/**
 * POST /api/admin/import-funcionarios
 *
 * Importa lista de funcion√°rios de um CSV e cria job para consultar SERPRO
 *
 * Body:
 * {
 *   tenant_code: "CLIENTE_01",
 *   funcionarios: [
 *     { cpf: "12345678900", grupo: "COMURG", cargo: "Auxiliar" },
 *     { cpf: "98765432100", grupo: "SECRETARIA", cargo: "Gerente" }
 *   ]
 * }
 */
router.post('/import-funcionarios', authMiddleware, async (c) => {
  const { tenant_code, funcionarios } = await c.req.json();

  // Valida√ß√µes
  if (!tenant_code || !funcionarios || !Array.isArray(funcionarios)) {
    return c.json({ error: 'Dados inv√°lidos' }, 400);
  }

  try {
    // 1. Inserir funcion√°rios no D1
    const insertStmt = c.env.DB.prepare(`
      INSERT INTO funcionarios (tenant_code, cpf, grupo, cargo, salario)
      VALUES (?, ?, ?, ?, ?)
      ON CONFLICT(tenant_code, cpf) DO UPDATE SET
        grupo = excluded.grupo,
        cargo = excluded.cargo,
        salario = excluded.salario,
        updated_at = CURRENT_TIMESTAMP
    `);

    const batch = funcionarios.map(f =>
      insertStmt.bind(
        tenant_code,
        f.cpf,
        f.grupo || null,
        f.cargo || null,
        f.salario || null
      )
    );

    await c.env.DB.batch(batch);

    // 2. Criar job para consultar SERPRO em background
    const cpfs = funcionarios.map(f => f.cpf);

    await c.env.DB.prepare(`
      INSERT INTO jobs_queue (type, tenant_code, status, data_json, items_total)
      VALUES (?, ?, ?, ?, ?)
    `).bind(
      'consultar_cpf_batch',
      tenant_code,
      'pending',
      JSON.stringify({ cpfs }),
      cpfs.length
    ).run();

    // 3. Log de auditoria
    await c.env.DB.prepare(`
      INSERT INTO audit_logs (user_id, action, entity_type, metadata)
      VALUES (?, ?, ?, ?)
    `).bind(
      c.get('userId'),
      'import',
      'funcionarios',
      JSON.stringify({ tenant_code, count: funcionarios.length })
    ).run();

    return c.json({
      success: true,
      message: `${funcionarios.length} funcion√°rios importados`,
      job_created: true,
      tenant_code
    });

  } catch (error: any) {
    console.error('Erro ao importar funcion√°rios:', error);
    return c.json({ error: error.message }, 500);
  }
});

export default router;
```

**Checklist:**
- [ ] Criar `src/routes/dados.routes.ts`
- [ ] Adicionar rota no `index.ts`: `app.route('/api/admin', dadosRouter)`
- [ ] Testar com curl/Postman

---

## üì° TAREFA 3: Endpoint - Listar Funcion√°rios (Dashboard)

**No mesmo arquivo:** `backend/workers/api/src/routes/dados.routes.ts`

```typescript
/**
 * GET /api/admin/tenants/:code/funcionarios
 *
 * Lista funcion√°rios de um tenant com dados do cache SERPRO
 *
 * Response:
 * {
 *   funcionarios: [...],
 *   total: 123,
 *   cache_stats: { cached: 100, pending: 23 }
 * }
 */
router.get('/tenants/:code/funcionarios', authMiddleware, async (c) => {
  const tenantCode = c.req.param('code');

  try {
    // Query principal: JOIN com cache SERPRO
    const { results } = await c.env.DB.prepare(`
      SELECT
        f.id,
        f.cpf,
        f.grupo,
        f.cargo,
        f.salario,

        -- Dados do cache SERPRO (se existir)
        COALESCE(cache.nome, f.nome_importado) as nome,
        cache.nascimento,
        cache.situacao_codigo,
        cache.situacao_descricao,
        cache.updated_at as ultima_consulta_serpro,

        -- Dados enriquecidos
        f.esta_morto,
        f.ano_obito,
        f.recebe_beneficio,
        f.qual_beneficio,
        f.socio_empresa,
        f.qtd_empresas,
        f.doador_campanha,
        f.valor_doacoes,
        f.candidato,
        f.sancionado_ceis,
        f.sancionado_ofac,

        -- Status do cache
        CASE
          WHEN cache.cpf IS NULL THEN 'pending'
          WHEN cache.expires_at < datetime('now') THEN 'expired'
          ELSE 'cached'
        END as cache_status

      FROM funcionarios f
      LEFT JOIN serpro_cpf_cache cache ON f.cpf = cache.cpf
      WHERE f.tenant_code = ?
      ORDER BY f.id
    `).bind(tenantCode).all();

    // Estat√≠sticas do cache
    const cached = results.filter(r => r.cache_status === 'cached').length;
    const pending = results.filter(r => r.cache_status === 'pending').length;
    const expired = results.filter(r => r.cache_status === 'expired').length;

    return c.json({
      funcionarios: results,
      total: results.length,
      cache_stats: {
        cached,
        pending,
        expired,
        percentage: results.length > 0 ? Math.round((cached / results.length) * 100) : 0
      },
      tenant_code: tenantCode
    });

  } catch (error: any) {
    console.error('Erro ao listar funcion√°rios:', error);
    return c.json({ error: error.message }, 500);
  }
});
```

**Checklist:**
- [ ] Implementar endpoint GET
- [ ] Testar com tenant existente
- [ ] Validar formato JSON

---

## ‚öôÔ∏è TAREFA 4: Processador de Jobs

**Arquivo:** `backend/workers/api/src/cron/process-jobs.ts` (novo)

```typescript
import type { Env } from '../types/api.types';
import { consultarCPF } from '../services/cpf.service';

/**
 * Processador de jobs em background
 * Executado via Cron Trigger (a cada 1 hora)
 */
export async function processJobs(env: Env): Promise<void> {
  console.log('[Cron] Iniciando processamento de jobs...');

  try {
    // 1. Buscar pr√≥ximo job pendente (prioridade + mais antigo)
    const job = await env.DB.prepare(`
      SELECT * FROM jobs_queue
      WHERE status = 'pending'
        AND (next_retry_at IS NULL OR next_retry_at <= datetime('now'))
      ORDER BY priority ASC, created_at ASC
      LIMIT 1
    `).first();

    if (!job) {
      console.log('[Cron] Nenhum job pendente');
      return;
    }

    console.log(`[Cron] Processando job #${job.id} (${job.type})`);

    // 2. Marcar como processando
    await env.DB.prepare(`
      UPDATE jobs_queue
      SET status = 'processing', started_at = datetime('now')
      WHERE id = ?
    `).bind(job.id).run();

    // 3. Processar conforme tipo
    if (job.type === 'consultar_cpf_batch') {
      await processConsultarCpfBatch(job, env);
    } else if (job.type === 'refresh_cache_cpf') {
      await processRefreshCacheCpf(job, env);
    } else {
      console.error(`[Cron] Tipo de job desconhecido: ${job.type}`);
    }

  } catch (error: any) {
    console.error('[Cron] Erro ao processar jobs:', error);
  }
}

/**
 * Processar job: consultar_cpf_batch
 * Consulta m√∫ltiplos CPFs no SERPRO e salva no cache
 */
async function processConsultarCpfBatch(job: any, env: Env): Promise<void> {
  const { cpfs } = JSON.parse(job.data_json);
  let processed = 0;
  let failed = 0;

  for (const cpf of cpfs) {
    try {
      // Verificar se j√° est√° no cache (e n√£o expirou)
      const cached = await env.DB.prepare(`
        SELECT cpf FROM serpro_cpf_cache
        WHERE cpf = ? AND expires_at > datetime('now')
      `).bind(cpf).first();

      if (cached) {
        console.log(`[Cron] CPF ${cpf} j√° est√° em cache v√°lido`);
        processed++;
        continue;
      }

      // Consultar SERPRO (üí∞ CUSTO!)
      console.log(`[Cron] Consultando CPF ${cpf} no SERPRO...`);
      const response = await consultarCPF(cpf, env);

      // Salvar no cache
      await env.DB.prepare(`
        INSERT INTO serpro_cpf_cache
        (cpf, nome, nascimento, situacao_codigo, situacao_descricao, dados_json, expires_at)
        VALUES (?, ?, ?, ?, ?, ?, datetime('now', '+90 days'))
        ON CONFLICT(cpf) DO UPDATE SET
          nome = excluded.nome,
          nascimento = excluded.nascimento,
          situacao_codigo = excluded.situacao_codigo,
          situacao_descricao = excluded.situacao_descricao,
          dados_json = excluded.dados_json,
          updated_at = datetime('now'),
          expires_at = excluded.expires_at,
          consultas_count = consultas_count + 1
      `).bind(
        cpf,
        response.nome,
        response.nascimento,
        response.situacao.codigo,
        response.situacao.descricao,
        JSON.stringify(response)
      ).run();

      // Log de uso (para billing)
      await env.DB.prepare(`
        INSERT INTO serpro_usage
        (user_id, tenant_code, api_name, document, cost, response_status)
        VALUES (?, ?, ?, ?, ?, ?)
      `).bind(
        'system',
        job.tenant_code,
        'cpf',
        cpf,
        0.50, // Custo por consulta CPF
        200
      ).run();

      processed++;

      // Rate limit: 60 req/min = 1 req/segundo
      await new Promise(resolve => setTimeout(resolve, 1000));

    } catch (error: any) {
      console.error(`[Cron] Erro ao consultar CPF ${cpf}:`, error);
      failed++;
    }

    // Atualizar progresso
    const progress = Math.round((processed + failed) / cpfs.length * 100);
    await env.DB.prepare(`
      UPDATE jobs_queue
      SET progress = ?, items_processed = ?, items_failed = ?
      WHERE id = ?
    `).bind(progress, processed, failed, job.id).run();
  }

  // Marcar como conclu√≠do
  await env.DB.prepare(`
    UPDATE jobs_queue
    SET status = 'completed', completed_at = datetime('now'), progress = 100
    WHERE id = ?
  `).bind(job.id).run();

  console.log(`[Cron] Job #${job.id} conclu√≠do: ${processed} OK, ${failed} falhas`);
}

/**
 * Processar job: refresh_cache_cpf
 * Re-consulta CPFs expirados
 */
async function processRefreshCacheCpf(job: any, env: Env): Promise<void> {
  // TODO: Implementar refresh de cache expirado
}
```

**Checklist:**
- [ ] Criar `src/cron/process-jobs.ts`
- [ ] Implementar `processConsultarCpfBatch()`
- [ ] Testar localmente

---

## ‚è∞ TAREFA 5: Configurar Cron Trigger

**Arquivo:** `backend/workers/api/wrangler.toml`

```toml
# ... configura√ß√£o existente ...

[triggers]
crons = ["0 */1 * * *"]  # A cada 1 hora
```

**Arquivo:** `backend/workers/api/src/index.ts`

```typescript
// ... imports existentes ...
import { processJobs } from './cron/process-jobs';

// ... c√≥digo existente ...

// Adicionar handler de cron
export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext) {
    return app.fetch(request, env, ctx);
  },

  // Handler de cron
  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext) {
    ctx.waitUntil(processJobs(env));
  }
};
```

**Checklist:**
- [ ] Adicionar `[triggers]` no wrangler.toml
- [ ] Adicionar `scheduled()` handler
- [ ] Deploy
- [ ] Testar cron: `npx wrangler dev --test-scheduled`

---

## üß™ TAREFA 6: Testes

### Teste 1: Importar Funcion√°rios
```bash
curl -X POST https://investigaree-api.chatbotimoveis.workers.dev/api/admin/import-funcionarios \
  -H "Authorization: Bearer $FIREBASE_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "tenant_code": "CLIENTE_01",
    "funcionarios": [
      { "cpf": "12345678900", "grupo": "COMURG", "cargo": "Auxiliar" },
      { "cpf": "98765432100", "grupo": "SECRETARIA", "cargo": "Gerente" }
    ]
  }'
```

**Resultado esperado:**
```json
{
  "success": true,
  "message": "2 funcion√°rios importados",
  "job_created": true
}
```

### Teste 2: Verificar Job Criado
```bash
npx wrangler d1 execute investigaree-db --remote \
  --command="SELECT * FROM jobs_queue ORDER BY id DESC LIMIT 1"
```

### Teste 3: Processar Job Manualmente
```bash
# Chamar endpoint manual (criar um para testes):
curl -X POST https://investigaree-api.chatbotimoveis.workers.dev/api/admin/process-jobs \
  -H "Authorization: Bearer $FIREBASE_TOKEN"
```

### Teste 4: Listar Funcion√°rios
```bash
curl https://investigaree-api.chatbotimoveis.workers.dev/api/admin/tenants/CLIENTE_01/funcionarios \
  -H "Authorization: Bearer $FIREBASE_TOKEN"
```

**Resultado esperado:**
```json
{
  "funcionarios": [
    {
      "id": 1,
      "cpf": "12345678900",
      "nome": "JOAO DA SILVA",
      "grupo": "COMURG",
      "cache_status": "cached"
    }
  ],
  "total": 2,
  "cache_stats": { "cached": 2, "pending": 0 }
}
```

**Checklist:**
- [ ] Teste 1: Import funcion√°rios ‚úì
- [ ] Teste 2: Job criado ‚úì
- [ ] Teste 3: Job processado ‚úì
- [ ] Teste 4: Dashboard l√™ dados ‚úì

---

## üìö TAREFA 7: Documenta√ß√£o para Agent 3

**Arquivo:** `.agents/agent-2-backend/SISTEMA_DADOS_DEPLOYED.md`

```markdown
# Sistema de Dados - DEPLOYED

## Endpoints Dispon√≠veis

### Importar Funcion√°rios
POST /api/admin/import-funcionarios
- Importa CSV de funcion√°rios
- Cria job para consultar SERPRO em background

### Listar Funcion√°rios (Dashboard)
GET /api/admin/tenants/:code/funcionarios
- Retorna funcion√°rios com dados do cache
- CUSTO: R$ 0,00 (l√™ cache D1)

## Fluxo de Dados

1. Admin importa CSV
2. Backend cria job na fila
3. Cron processa job (1x/hora)
4. SERPRO consultado em background
5. Dados salvos no cache (90 dias)
6. Dashboard l√™ cache (gr√°tis!)

## Para Agent 3

Use este endpoint:
GET /api/admin/tenants/CLIENTE_01/funcionarios

Retorna JSON com todos os funcion√°rios + cache SERPRO.
```

**Checklist:**
- [ ] Criar documenta√ß√£o
- [ ] Atualizar `API_DEPLOYED.md`
- [ ] Notificar Agent 3

---

## üöÄ TAREFA 8: Deploy

```bash
cd backend/workers/api

# 1. Aplicar migration
npx wrangler d1 execute investigaree-db --remote \
  --file=../../database/migrations/002_dados_investigacao.sql

# 2. Deploy worker
npx wrangler deploy

# 3. Verificar sa√∫de
curl https://investigaree-api.chatbotimoveis.workers.dev/health
```

**Checklist:**
- [ ] Migration aplicada ‚úì
- [ ] Worker deployado ‚úì
- [ ] Health check OK ‚úì
- [ ] Cron configurado ‚úì

---

## ‚úÖ CRIT√âRIOS DE CONCLUS√ÉO

Esta tarefa est√° **COMPLETA** quando:

1. ‚úÖ 4 novas tabelas criadas no D1
2. ‚úÖ Endpoint de importa√ß√£o funcionando
3. ‚úÖ Endpoint de leitura (dashboard) funcionando
4. ‚úÖ Processador de jobs implementado
5. ‚úÖ Cron trigger configurado
6. ‚úÖ Testes passando
7. ‚úÖ Documenta√ß√£o criada
8. ‚úÖ Agent 3 notificado

**Resultado Final:**
- Dashboard pode ler dados do D1 (GR√ÅTIS!)
- SERPRO consultado em background (controlado)
- Sistema escal√°vel e econ√¥mico

---

**FIM DA ESPECIFICA√á√ÉO** ‚úÖ

Boa sorte, Agent 2! üöÄ
